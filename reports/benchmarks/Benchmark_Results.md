# PRISM Engine Benchmark Results

- **Date**: 2025-12-08
- **Commit**: `cd6ee0e`
- **Generated**: 2025-12-08 21:43:40

## Overview

This document summarizes the benchmark results for the PRISM Engine.
The benchmarks cover four main areas:

1. **Engine Correctness**: Validates lens behavior on synthetic signals
2. **Engine Performance**: Measures temporal analysis throughput
3. **Overnight Analysis**: Tests overnight script components
4. **ML/Seismometer**: Validates ML pipeline components

## Quick Summary

| Suite | Status | Tests/Benchmarks | Runtime | Notes |
|-------|--------|------------------|---------|-------|
| Correctness | PASS | 7 scenarios, 3/3 checks | 3.38s | Synthetic signal validation |
| Performance | - | Not run | - | - |
| Overnight | - | Not run | - | - |
| ML/Seismometer | - | Not run | - | - |

## Detailed Reports

- [Engine Correctness](Engine_Correctness.md)
- [Engine Performance](Engine_Performance.md)
- [Overnight Analysis](Overnight_Analysis_Benchmark.md)
- [ML/Seismometer](ML_Seismometer_Benchmark.md)

## Interpretation

- **Correctness**: All scenarios passed. Lenses correctly detect expected signal properties in synthetic data.

---
*Report generated by PRISM Engine Benchmark Harness v1.0*